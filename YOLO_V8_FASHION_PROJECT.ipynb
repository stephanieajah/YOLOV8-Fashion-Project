{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OsrMpmijKsc"
      },
      "source": [
        "#**Smart Wardrobe: Integrating YOLOv8 and Large Language Models in Fashion Styling.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjyXp5ivjE9R"
      },
      "source": [
        "###1. Install YOLOv8 and Import YOLO and other Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DQTAKNtc3Czu",
        "outputId": "e027c9b3-9786-42cb-8ead-238173ee0e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.40-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.40-py3-none-any.whl (898 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m898.5/898.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.40 ultralytics-thop-2.0.12\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import yaml\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac2LgJlakXOj"
      },
      "source": [
        "###2. Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51ZPxVZJkmms",
        "outputId": "aa041ef9-f795-44ff-e8aa-f2a6d444f3eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOv8n-cls summary: 99 layers, 2,719,288 parameters, 2,719,288 gradients, 4.4 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "#Load the model\n",
        "model = YOLO(\"yolov8n-cls.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2LL1iX3knZO"
      },
      "source": [
        "###3. Training and testing the Model\n",
        "\n",
        "During training, YOLO internally validates the model. This process ensures that the model isn't just memorizing the training data but is generalizing well to unseen examples. This process will also download the FashionMnist dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AchHMDLOa6w",
        "outputId": "2772d3d9-5d85-4e86-84d5-0158bb727c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.yaml, data=fashion-mnist, epochs=10, time=None, patience=100, batch=16, imgsz=28, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train\n",
            "\n",
            "Dataset not found ‚ö†Ô∏è, missing path /content/datasets/fashion-mnist, attempting download...\n",
            "Downloading https://ultralytics.com/assets/fashion-mnist.zip to '/content/datasets/fashion-mnist.zip'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47.0M/47.0M [00:00<00:00, 83.9MB/s]\n",
            "Unzipping /content/datasets/fashion-mnist.zip to /content/datasets/fashion-mnist...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70023/70023 [00:20<00:00, 3383.94file/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset download success ‚úÖ (26.7s), saved to \u001b[1m/content/datasets/fashion-mnist\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/fashion-mnist/train... found 60000 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/fashion-mnist/test... found 10000 images in 10 classes ‚úÖ \n",
            "Overriding model.yaml nc=1000 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
            "YOLOv8n-cls summary: 99 layers, 1,451,098 parameters, 1,451,098 gradients, 3.4 GFLOPs\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train', view at http://localhost:6006/\n",
            "WARNING ‚ö†Ô∏è imgsz=[28] must be multiple of max stride 32, updating to [32]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/fashion-mnist/train... 60000 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60000/60000 [00:16<00:00, 3739.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/fashion-mnist/train.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/fashion-mnist/test... 10000 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:02<00:00, 3795.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/fashion-mnist/test.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 32 train, 32 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10         0G      2.323         16         32:   0%|          | 4/3750 [00:00<12:00,  5.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/10         0G       2.34         16         32:   0%|          | 7/3750 [00:01<09:22,  6.66it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 15.0MB/s]\n",
            "       1/10         0G      1.449         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [07:38<00:00,  8.18it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 22.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.723      0.994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/10         0G     0.9406         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:51<00:00,  9.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.793      0.996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/10         0G     0.8194         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:37<00:00,  9.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.822      0.997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/10         0G      0.732         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:19<00:00,  9.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 22.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.854      0.998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/10         0G     0.6714         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:25<00:00,  9.72it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 22.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.857      0.998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/10         0G     0.6292         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:23<00:00,  9.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.868      0.998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/10         0G     0.5938         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:26<00:00,  9.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.864      0.998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/10         0G     0.5642         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:23<00:00,  9.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.875      0.999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/10         0G     0.5419         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:21<00:00,  9.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 22.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.874      0.999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/10         0G     0.5201         16         32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3750/3750 [06:18<00:00,  9.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:14<00:00, 21.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.879      0.999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "10 epochs completed in 1.138 hours.\n",
            "Optimizer stripped from runs/classify/train/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating runs/classify/train/weights/best.pt...\n",
            "WARNING ‚ö†Ô∏è validating an untrained model YAML will result in 0 mAP.\n",
            "Ultralytics 8.3.40 üöÄ Python-3.10.12 torch-2.5.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1,447,690 parameters, 0 gradients, 3.3 GFLOPs\n",
            "WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/datasets/fashion-mnist/train... found 60000 images in 10 classes ‚úÖ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/datasets/fashion-mnist/test... found 10000 images in 10 classes ‚úÖ \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:13<00:00, 23.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all      0.879      0.999\n",
            "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Train the model\n",
        "results = model.train(data=\"fashion-mnist\", epochs=10, imgsz=28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LRnIrQPlYJk"
      },
      "source": [
        "### Running Inference on the model Using some samples from the test data\n",
        "Defined the class labels for Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4XjU_OVh5tV"
      },
      "outputs": [],
      "source": [
        "# Define the manual class labels for Fashion MNIST\n",
        "class_names = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z27t9TYRh8XW",
        "outputId": "c7e1cf3c-2d03-4491-81e7-48d6925edf9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/datasets/fashion-mnist/test/9/1007.png: 32x32 9 0.95, 7 0.05, 5 0.00, 8 0.00, 3 0.00, 6.5ms\n",
            "Speed: 13.8ms preprocess, 6.5ms inference, 0.2ms postprocess per image at shape (1, 3, 32, 32)\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Predicted class: Ankle Boot, Confidence: 0.95\n"
          ]
        }
      ],
      "source": [
        "# Inference for a specific image\n",
        "results = model.predict(source=\"/content/datasets/fashion-mnist/test/9/1007.png\", save=True)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        # Get the index of the top predicted class\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        # Map the class index to the class name using the previously defined list\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        # Get the confidence score for the top class\n",
        "        confidence = result.probs.top1conf.item()\n",
        "\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrTe5JVxiD3f",
        "outputId": "943e9a3b-817d-4fa1-f398-1628ce2c1088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/datasets/fashion-mnist/test/0/1049.png: 32x32 0 0.94, 6 0.06, 3 0.00, 2 0.00, 4 0.00, 3.7ms\n",
            "Speed: 1.8ms preprocess, 3.7ms inference, 0.1ms postprocess per image at shape (1, 3, 32, 32)\n",
            "Results saved to \u001b[1mruns/classify/train3\u001b[0m\n",
            "Predicted class: T-shirt/top, Confidence: 0.94\n"
          ]
        }
      ],
      "source": [
        "# Inference for a more images\n",
        "results = model.predict(source=\"/content/datasets/fashion-mnist/test/0/1049.png\", save=True)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        # Get the index of the top predicted class\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        # Map the class index to the class name using the previously defined list\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        # Get the confidence score for the top class\n",
        "        confidence = result.probs.top1conf.item()\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC5mNmi0nB2g",
        "outputId": "70bed284-d864-4694-881d-e7199c91aa47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/datasets/fashion-mnist/test/7/1040.png: 32x32 7 1.00, 5 0.00, 9 0.00, 8 0.00, 0 0.00, 6.2ms\n",
            "Speed: 2.5ms preprocess, 6.2ms inference, 0.1ms postprocess per image at shape (1, 3, 32, 32)\n",
            "Results saved to \u001b[1mruns/classify/train4\u001b[0m\n",
            "Predicted class: Sneaker, Confidence: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Inference for a more images\n",
        "results = model.predict(source=\"/content/datasets/fashion-mnist/test/7/1040.png\", save=True)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        # Get the index of the top predicted class\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        # Map the class index to the class name using the previously defined list\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        # Get the confidence score for the top class\n",
        "        confidence = result.probs.top1conf.item()\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPJUMWnBhb21",
        "outputId": "4ab0b738-1b43-48e1-fc39-ca7d45b5b9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/datasets/fashion-mnist/test/8/1564.png: 32x32 8 1.00, 4 0.00, 0 0.00, 6 0.00, 2 0.00, 7.5ms\n",
            "Speed: 2.2ms preprocess, 7.5ms inference, 0.1ms postprocess per image at shape (1, 3, 32, 32)\n",
            "Results saved to \u001b[1mruns/classify/train5\u001b[0m\n",
            "Predicted class: Bag, Confidence: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Inference for a more images\n",
        "results = model.predict(source=\"/content/datasets/fashion-mnist/test/8/1564.png\", save=True)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        # Get the index of the top predicted class\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        # Map the class index to the class name using the previously defined list\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        # Get the confidence score for the top class\n",
        "        confidence = result.probs.top1conf.item()\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu5HMYtJ0LKD"
      },
      "source": [
        "### Testing on Google Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRwBe06LxdWy",
        "outputId": "75bfcf13-cfff-422d-d7d7-85a1c43e2fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x640 6 0.32, 8 0.16, 2 0.11, 0 0.11, 4 0.11, 134.8ms\n",
            "Speed: 0.0ms preprocess, 134.8ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/classify/train6\u001b[0m\n",
            "Predicted class: Shirt, Confidence: 0.32\n"
          ]
        }
      ],
      "source": [
        "# Using an image from the web\n",
        "image_url = \"https://images.unsplash.com/photo-1521572163474-6864f9cf17ab?q=80&w=1780&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
        "\n",
        "# Download the image from the URL\n",
        "response = requests.get(image_url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Preprocessing the image for YOLO\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x if x.shape[0] == 3 else x.repeat(3, 1, 1))\n",
        "])\n",
        "img_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "# Perform inference\n",
        "results = model.predict(source=img_tensor, save=True)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        confidence = result.probs.top1conf.item()\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkVmDaId5rBb"
      },
      "source": [
        "# **STYLING ADVICE PORTION**\n",
        "###**PARSING THE IMAGE TO AN LLM TO GIVE STYLING ADVICE**\n",
        "The LLM chosen is OpenAI 's ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0v1bqnLS1_d"
      },
      "source": [
        "###Testing my API and GPT 4's advice to see if the advice is suitable for the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHseZZtT6Frw",
        "outputId": "747c26a4-5682-4228-81de-b50deb1742e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Denim Chic: Team up the shirt with a pair of blue skinny jeans and white low-top sneakers for a casual yet stylish look. Don't forget to accessorize with a minimalistic pendant and watch.\n",
            "\n",
            "2. Sophisticated Business: Wear your shirt with a well-tailored suit, a pair of oxfords, and a nice tie. This outfit is perfect for a meeting or business affair.\n",
            "\n",
            "3. Summer Breeze: Pair a light colored shirt with cotton shorts, adding espadrilles and sunglasses for a perfect summer day look.\n",
            "\n",
            "4. Cozy Layering: Wear the shirt under a crew-neck sweater, pair it with chinos and monk strap shoes for a relaxed yet refined appearance.\n",
            "\n",
            "5. Casual Friday: For a trendy office look, pair up your shirt with black jeans, add a leather belt, and loafers. Roll up the shirt sleeves for a cool, casual flair.\n",
            "\n",
            "6. Trendy Hipster: Wear your shirt with distressed skinny jeans, and add some stylishly rugged boots. Layer with a denim jacket to amp up the hipster vibe.\n",
            "\n",
            "7. Classic and Dapper: Button up your shirt and pair it with tailored trousers and brogues for a clean and timeless look. \n",
            "\n",
            "8. Laid-back Casual: Leave your shirt slightly open and pair it with cargo shorts and sneakers for a laid-back look. \n",
            "\n",
            "9. Fashion-forward: For a more daring look, pair your brightly colored shirt with contrasting pants, like a pink shirt with turquoise pants. Accessorize with a chunky necklace for added edge. \n",
            "\n",
            "10. Layer it Right: Wear your shirt under an open-front cardigan with jeans and ballet flats for a comfy, chic outfit.\n"
          ]
        }
      ],
      "source": [
        "# Set your API key\n",
        "client =OpenAI(api_key=\"INSERT-API-KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[\n",
        "      {'role': 'user',\n",
        "       'content': 'You are a fashion expert. Suggest stylish outfit combinations for someone wearing a shirt.'}\n",
        "  ]\n",
        ")\n",
        "\n",
        "message = response.choices[0].message.content\n",
        "print(message)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZvtfkYLS_DK"
      },
      "source": [
        "### Trying to test the code to give fashion advice on a google image after the url has been inputed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4MNoYk-IJvn",
        "outputId": "8d94a3c6-092c-42ce-f338-645fd5b43a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x640 6 0.32, 8 0.16, 2 0.11, 0 0.11, 4 0.11, 114.9ms\n",
            "Speed: 0.0ms preprocess, 114.9ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/classify/train7\u001b[0m\n",
            "Predicted class: Shirt, Confidence: 0.32\n",
            "1. Shirt + Straight-leg Jeans + White Sneakers: This combo is perfect for a casual day-out. Add a leather watch or bracelet to take your outfit to the next level.\n",
            "\n",
            "2. Shirt + Blazer + Dress Pants + Dress Shoes: Ideal for a business-casual or professional setting. Opt for solid color shirts and keep your blazer and pants in matching shades. A classic pair of dress shoes will seal this elegant look.\n",
            "\n",
            "3. Shirt + Jumper + Chinos + Loafers: A combination of a shirt under a jumper (wool or cotton), paired with chinos and loafers offers a cozy yet smart look. This outfit is great for autumn.\n",
            "\n",
            "4. Shirt + Leather Jacket + Black Jeans + Boots: For a bit of an edge, wearing a shirt under a leather jacket with black jeans and boots is a great pick. You'll look effortlessly cool.\n",
            "\n",
            "5. Shirt + Shorts + Boat Shoes: For those hot summer days, a button-down shirt with shorts makes a perfect outfit. A pair of boat shoes, aviator sunglasses, and a nice hat would add the finishing touches.\n",
            "\n",
            "6. Shirt + Vest + Dress Pant + Oxfords: This combination offers a formal atmosphere with a sense of fashion. Opt for a fitted vest to make it look sleek. \n",
            "\n",
            "7. Shirt + Denim Jacket + Skinny Jeans + White Sneakers: This is perfect for casual outings or even a casual Friday at work. The denim-on-denim look can suit just about anyone when done right. \n",
            "\n",
            "8. Shirt + Trench Coat + Slacks + Dress Shoes: Ideal for a rainy or chill day, pairing your shirt with a classic trench coat gives an air of sophistication. Keep it neutral toned for a more classic look.\n",
            "\n",
            "9. Shirt + Cargo Pants + Boots: For a rugged, outdoorsy look, combine a durable work shirt with cargo pants and boots. You may add accessories such as a beanie or a backpack.\n",
            "\n",
            "10. Shirt + Suit + Dress Shoes: Nothing beats the classic shirt with a suit look for formal events. The solid shirt color would work great with a patterned tie, or vice versa. Choose dress shoes to match the color of your suit.\n"
          ]
        }
      ],
      "source": [
        "# Using an image from the web\n",
        "image_url = \"https://images.unsplash.com/photo-1521572163474-6864f9cf17ab?q=80&w=1780&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
        "\n",
        "# Download the image from the URL\n",
        "response = requests.get(image_url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Preprocessing the image for YOLO\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x if x.shape[0] == 3 else x.repeat(3, 1, 1))\n",
        "])\n",
        "img_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "# Perform inference\n",
        "results = model.predict(source=img_tensor, save=True)\n",
        "\n",
        "# Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        confidence = result.probs.top1conf.item()\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n",
        "\n",
        "# Set your API key\n",
        "client =OpenAI(api_key=\"INSERT-API-KEY\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {'role': 'user',\n",
        "         'content': f'You are a fashion expert. Suggest stylish outfit combinations for someone wearing a {predicted_class_name}.'}\n",
        "    ]\n",
        ")\n",
        "\n",
        "message = response.choices[0].message.content\n",
        "print(message)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG0Ohi_oTIrj"
      },
      "source": [
        "### Giving fashion advice after the user uploads their own image\n",
        "Will be uploading the image of a bag i found online"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "AxqIE6o4IJrL",
        "outputId": "540d85e2-1833-477b-a6f7-549a7eaf75bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6ec3cc1-9b5c-4cfd-8492-8305cb3f464b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d6ec3cc1-9b5c-4cfd-8492-8305cb3f464b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving a bag.jpg to a bag (1).jpg\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Upload the image\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljDdWZsoIJbR",
        "outputId": "f3c15dae-fd37-49ed-e27b-69a88b5a1e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 640x640 6 0.36, 4 0.16, 8 0.15, 2 0.10, 3 0.09, 111.3ms\n",
            "Speed: 0.1ms preprocess, 111.3ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/classify/train12\u001b[0m\n",
            "Predicted class: Shirt, Confidence: 0.36\n",
            "1. Casual Look: A shirt in checked or solid colors paired with dark denim jeans. Suede loafers or sneakers would finish off the look perfectly. \n",
            "\n",
            "2. Formal Look: A crisp white shirt paired with slim-fit black trousers. These can be accessorized with a monochromatic tie, leather belt, and a pair of patent leather oxfords. \n",
            "\n",
            "3. Semi-Formal Look: A pastel-colored shirt paired with chinos. Match it with a leather belt and a pair of loafers or brogues. \n",
            "\n",
            "4. Date Look: A dark-colored shirt (preferably black or navy) paired with a tailored blazer and slim-fit jeans. Ankle boots or loafers would complete this outfit.\n",
            "\n",
            "5. Summer Look: A bright, short-sleeved shirt with white or light-colored linen trousers. Complete the look with a pair of white sneakers.\n",
            "\n",
            "6. Winter Look: A flannel shirt paired with a warm cardigan, dark jeans, and a pair of stylish boots. \n",
            "\n",
            "7. Business Casual Look: A light blue or white dress shirt, paired with navy chinos and a pair of brown or black brogues. \n",
            "\n",
            "8. Beach Look: A loose, colorful Hawaiian shirt paired with khaki shorts or premium swim shorts, and a pair of slide sandals.\n",
            "\n",
            "9. Bohemian Look: A loose, natural fiber shirt with unique patterns or embroidery, paired with loose trousers, boots, and lots of jewelry.\n",
            "\n",
            "10. Luxury Evening Look: A sleek, silk dress shirt with a high-quality suit or tuxedo, polished dress shoes, and a simple but elegant watch.\n",
            "  \n",
            "Remember, fashion is about personal style and expressing yourself. Always wear outfits that reflect your personality and taste.\n"
          ]
        }
      ],
      "source": [
        "# Get the uploaded file path\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Open the uploaded image\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# Step 2: Preprocessing the image for YOLO\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x if x.shape[0] == 3 else x.repeat(3, 1, 1))\n",
        "])\n",
        "\n",
        "img_tensor = transform(img).unsqueeze(0)\n",
        "\n",
        "# Step 3: YOLO Prediction (Assuming 'model' is defined already)\n",
        "results = model.predict(source=img_tensor, save=True)\n",
        "\n",
        "# Step 4: Process the results\n",
        "for result in results:\n",
        "    if hasattr(result, \"probs\") and result.probs is not None:\n",
        "        predicted_class_idx = result.probs.top1\n",
        "        predicted_class_name = class_names[predicted_class_idx]\n",
        "        confidence = result.probs.top1conf.item()\n",
        "        print(f\"Predicted class: {predicted_class_name}, Confidence: {confidence:.2f}\")\n",
        "    else:\n",
        "        print(\"No predictions for this image.\")\n",
        "\n",
        "# Step 5: Ask OpenAI for fashion advice based on the predicted class\n",
        "client =OpenAI(api_key=\"INSERT-API-KEY\")\n",
        "\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': f'You are a fashion expert. Suggest stylish outfit combinations for someone wearing a {predicted_class_name}.'}]\n",
        ")\n",
        "\n",
        "message = response.choices[0].message.content\n",
        "print(message)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
